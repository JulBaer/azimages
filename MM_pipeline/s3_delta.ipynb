{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0fb2c00-5f86-4e04-bc1c-db96cb136d93",
   "metadata": {},
   "source": [
    "# # MM pipeline: Run the DeLTA tracking model over all folders\n",
    "\n",
    "This has originally been provided by Owen O'Connor and modified by Julian Baer to work with the pipeline to analyse mother machine images analysed with JB's pipeline.\n",
    "The delta post-processing script that creates a nice .csv that I import into R for analysis was provided by Simon van Vliet. The outputs are as followed:\n",
    "\n",
    "In the data frame we now have the following lineage information:\n",
    "\n",
    "- `id_seg`: the ordinal lineage id assigned by delta (contains cell+offspring), this index (offset by 1) in label image. Don't use this unless you need to interface wit label image\n",
    "- `id_cell`: a unique id for each cell, from birth to division. Always use this to access cell lineages.\n",
    "- `id_par`: the `id_cell` number of a cell's parent\n",
    "- `id_colony`: each cell in first frame is assigned a unique `id_colony` which is shared with all it's offspring. (e.g. use this to separate different colonies)\n",
    "- `id_d1`: the `id_cell` number of a cell's first offspring (old-pole)\n",
    "- `id_d2`: the `id_cell` number of a cell's second offspring (new-pole)\n",
    "- `id_sib`: the `id_cell` number of a cell's sibling\n",
    "- `generation`: cell generation: 0 for cells present in first frame, 1 for first generation of offspring, etc.\n",
    "- `age`: frame number relative to birth of cell, i.e. it goes from 0:T where T is life time of cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb71ca2-30ea-4214-9d97-75e5df8b504b",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Specify paths and variables in the s0_writeconfig.mat file:\n",
    "- `deltapath`  as I use a locally modified delta version that is not installed via conda or pip, I append the path to where I have that delta package stored and load from there. Please modify accordingly!! This modified version is included in the github repo.\n",
    "- `configpath` DeLTA uses it's own seperate config file. This is the path to the storage of this config file. This needs to point to the tracking model (hdf5) file. This hdf5 is large and not included in the github repo. You can download my mother-machine 2D model for cocci here: LINK\n",
    "- `configname` name of the DeLTA config file\n",
    "- `imageprototype` structure of the image naming scheme, all the ID numbers in it and the number format of the IDs\n",
    "- `orderprototype` corresponding structure of IDs. *p* = position; *c* = color channel; *t* = frame\n",
    "- `image_heigth` and `image_width` pad images to this size if they're smaller. 256x256 is also the size the tracking model has been trained for and it cannot be smaller than that. Never tried with bigger images... Your task! :)\n",
    "- `cropimages` a parameter in the creation of the position object of delta. No idea if this has an effect on tracking or only on their segmentation model\n",
    "- `driftcor` a parameter in the creation of the posiiton object of delta. Maybe you can use that?\n",
    "- `saveformats` you can save movies for the tracking, data in pickle or .mat formats (native delta outputs). Additionally, I anyway save a .csv for each movie with some (for me) easier-to-read formating.\n",
    "- `clearsaves` If True, delete all detected delta output before attempting to track. Useful if you're troubleshooting and want to make sure all previous attempts are erased\n",
    "- `savemovie` If True, save the Delta movie\n",
    "- `savemoviefreq` frequency of movie saving.\n",
    "- `features_list` delta features to track.\n",
    "\n",
    "\n",
    "\n",
    "### Load main config file. Adapt directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "070881ec-d800-4c7e-bc95-27538393d952",
   "metadata": {},
   "outputs": [],
   "source": [
    "mainconfigname = 'jbanalysisconfig_mm';\n",
    "configdir = 'C://Users/zinke/Documents/GitHub/azimages/julian/MM_pipeline';\n",
    "\n",
    "if not mainconfigname.endswith('.json'):\n",
    "    mainconfigname += '.json'\n",
    "    \n",
    "if not configdir.endswith('/'):\n",
    "    configdir += '/'\n",
    "\n",
    "import json\n",
    "# Read JSON data\n",
    "with open(configdir+mainconfigname, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Assign each key-value pair as a variable\n",
    "for key, value in data.items():\n",
    "    globals()[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e66bb80-51ac-4f22-880a-c6c36abed36f",
   "metadata": {},
   "source": [
    "### Check if the DeLTA config path is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4d3281e-6379-4255-be56-293c55062f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C://Users/zinke/Documents/GitHub/azimages/julian/delta/models/\n"
     ]
    }
   ],
   "source": [
    "print(configpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c797dde5-4570-47a2-b172-982691e595fa",
   "metadata": {},
   "source": [
    "### Load various packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e0e9480-8e2f-45e6-aea6-e06084b0c12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\/Users/zinke/Documents/GitHub/azimages/julian/delta_vjb/delta\\delta\\data.py:28: UserWarning: Could not load elastic deformations module.\n",
      "  warnings.warn(\"Could not load elastic deformations module.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration from: C:\\Users\\zinke\\Documents\\GitHub\\azimages\\julian\\delta\\models\\config_2D_JB-strix.json\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import sys\n",
    "import pathlib\n",
    "sys.path.append(deltapath)\n",
    "import glob\n",
    "\n",
    "import delta\n",
    "import delta.utilities as utils\n",
    "from delta.utilities import cfg\n",
    "from delta.delta_postprocess import delta_to_df #contains all the code to convert delta object\n",
    "\n",
    "import napari\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from skimage.segmentation import clear_border\n",
    "from scipy import ndimage \n",
    "import os\n",
    "from tifffile import imread, imwrite\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "def to_str(posixpath):\n",
    "    return str(posixpath.resolve())\n",
    "\n",
    "cfg.load_config(to_str(pathlib.Path(configpath + configname)))\n",
    "cfg.save_format = saveformats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b395bf-e926-408f-9083-16c03e618347",
   "metadata": {},
   "source": [
    "### Load in meta file and display head. Check if correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "512d082d-ff26-413c-8c63-534dbb7d93db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>replicate</th>\n",
       "      <th>pos</th>\n",
       "      <th>strain</th>\n",
       "      <th>dt</th>\n",
       "      <th>channel</th>\n",
       "      <th>Note</th>\n",
       "      <th>Exclude</th>\n",
       "      <th>MaxFr</th>\n",
       "      <th>type</th>\n",
       "      <th>aip_type</th>\n",
       "      <th>...</th>\n",
       "      <th>rotation</th>\n",
       "      <th>StageX</th>\n",
       "      <th>StageY</th>\n",
       "      <th>PxinUmX</th>\n",
       "      <th>PxinUmY</th>\n",
       "      <th>register</th>\n",
       "      <th>stardist</th>\n",
       "      <th>stardist_fails</th>\n",
       "      <th>delta</th>\n",
       "      <th>delta_fails</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s02</td>\n",
       "      <td>1</td>\n",
       "      <td>agr-I</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sAIP</td>\n",
       "      <td>AIP-I</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-62860.49788</td>\n",
       "      <td>-39324.74159</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s03</td>\n",
       "      <td>1</td>\n",
       "      <td>agr-I</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240.0</td>\n",
       "      <td>sAIP</td>\n",
       "      <td>AIP-I</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-59819.89317</td>\n",
       "      <td>-38749.07585</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s06</td>\n",
       "      <td>1</td>\n",
       "      <td>agr-I</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225.0</td>\n",
       "      <td>sAIP</td>\n",
       "      <td>AIP-I</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-60615.52819</td>\n",
       "      <td>-37553.06656</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s06</td>\n",
       "      <td>2</td>\n",
       "      <td>agr-I</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192.0</td>\n",
       "      <td>sAIP</td>\n",
       "      <td>AIP-I</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-61960.15363</td>\n",
       "      <td>-35559.99190</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s07</td>\n",
       "      <td>1</td>\n",
       "      <td>agr-II</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sAIP</td>\n",
       "      <td>AIP-II</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-57633.21060</td>\n",
       "      <td>-43430.12590</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  replicate  pos  strain   dt  channel  Note  Exclude  MaxFr  type aip_type  \\\n",
       "0       s02    1   agr-I  5.0        2   NaN      NaN    NaN  sAIP    AIP-I   \n",
       "1       s03    1   agr-I  5.0        4   NaN      NaN  240.0  sAIP    AIP-I   \n",
       "2       s06    1   agr-I  5.0        4   NaN      NaN  225.0  sAIP    AIP-I   \n",
       "3       s06    2   agr-I  5.0        5   NaN      NaN  192.0  sAIP    AIP-I   \n",
       "4       s07    1  agr-II  5.0        2   NaN      NaN    NaN  sAIP   AIP-II   \n",
       "\n",
       "   ...  rotation       StageX       StageY  PxinUmX  PxinUmY  register  \\\n",
       "0  ...      0.00 -62860.49788 -39324.74159    0.065    0.065      Done   \n",
       "1  ...      0.00 -59819.89317 -38749.07585    0.065    0.065      Done   \n",
       "2  ...     -0.25 -60615.52819 -37553.06656    0.065    0.065      Done   \n",
       "3  ...     -0.25 -61960.15363 -35559.99190    0.065    0.065      Done   \n",
       "4  ...      0.25 -57633.21060 -43430.12590    0.065    0.065      Done   \n",
       "\n",
       "  stardist  stardist_fails delta  delta_fails  \n",
       "0     Done             NaN   NaN          NaN  \n",
       "1     Done             NaN   NaN          NaN  \n",
       "2     Done             NaN   NaN          NaN  \n",
       "3     Done             NaN   NaN          NaN  \n",
       "4     Done             NaN   NaN          NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pd.read_csv(os.path.join(masterdir,metacsv))\n",
    "replicates = meta.replicate.unique()\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dcf615-3e9d-44cf-9198-bba8b4344340",
   "metadata": {},
   "source": [
    "# The actual tracking loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cd8397-d1cf-47af-b676-3e36b89f4764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s26, Pos 01:  22%|██████████████▉                                                    | 4/18 [48:58<2:55:54, 753.91s/it]"
     ]
    }
   ],
   "source": [
    "# Initialize counter\n",
    "saved_movies = 0\n",
    "\n",
    "# Create a blank reference image based on drift correction setting\n",
    "new_image_width = image_width\n",
    "new_image_height = image_height\n",
    "ref = None if driftcor else np.zeros((image_height, image_width), dtype=np.float32)\n",
    "\n",
    "# Process each row in the meta file\n",
    "for i in range(meta.shape[0]):\n",
    "    fails = ''\n",
    "    row = meta.iloc[i]\n",
    "\n",
    "    # Skip conditions\n",
    "    if row['delta'] == 'Done' or row['Exclude'] in ['excl', 'skip'] or row['stardist'] != 'Done':\n",
    "        continue\n",
    "\n",
    "    # Tracking condition\n",
    "    if row['type'] not in ['short', 'FLX']:\n",
    "        continue\n",
    "\n",
    "    # Setup directories\n",
    "    main_folder = os.path.join(masterdir, savedirname, row['replicate'], 'Chambers')\n",
    "    save_directory = os.path.join(main_folder, deltasavename)\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "    # Clear saved files if needed\n",
    "    if clearsaves:\n",
    "        for pattern in ['*Pos{}*mp4', '*Pos{}*csv']:\n",
    "            for file in Path(save_directory).glob(pattern.format(str(row['pos']).zfill(2))):\n",
    "                os.remove(file)\n",
    "\n",
    "    # Current position folder\n",
    "    curr_dir = os.path.join(main_folder, f'Pos{round(row[\"pos\"]):02d}')\n",
    "    if not os.path.exists(curr_dir):\n",
    "        continue\n",
    "\n",
    "    # List all image folders\n",
    "    chamber_folders = [f.path for f in os.scandir(curr_dir) if f.is_dir() and 'Chamb' in f.name]\n",
    "\n",
    "    # Process each chamber folder\n",
    "    for chami, chamber_folder in enumerate(tqdm(chamber_folders, desc=f\"{row['replicate']}, Pos {round(row['pos']):02d}\")):\n",
    "        try:\n",
    "            # Initialize reader and position object\n",
    "            reader = delta.utils.xpreader(Path(curr_dir), fileorder=orderprototype, prototype=imageprototype)\n",
    "            position_nb = chami\n",
    "            \n",
    "            # rois set to 0\n",
    "            rois_nb = 0\n",
    "            \n",
    "            # get list of all images\n",
    "            unprocessed = sorted(glob.glob((chamber_folders[chami]) + \"/*.tif\"))\n",
    "            \n",
    "            # create the delta position object\n",
    "            pos = delta.pipeline.Position(\n",
    "                position_nb=position_nb,\n",
    "                reader=reader,\n",
    "                models=delta.utils.loadmodels(),\n",
    "                drift_correction=driftcor,\n",
    "                crop_windows=cropimages\n",
    "                )\n",
    "\n",
    "            # features to extract\n",
    "            features = tuple(features_list)\n",
    "\n",
    "            # run delta pre-processing                       \n",
    "            pos.preprocess(rotation_correction=delta.config.rotation_correction, reference = ref)\n",
    "            \n",
    "            # get list of frames/timepoints and go over all images and segmentation files\n",
    "            # to pad them to 256x256.\n",
    "            # for the segmentation images, transform them to binary masks and make sure\n",
    "            # that there's always a gap between cells\n",
    "            frames = [f for f in range(pos.reader.timepoints)]\n",
    "            for trans_frameN in unprocessed:\n",
    "                # read in current image\n",
    "                trans_frame = cv2.imread(str(trans_frameN),cv2.IMREAD_ANYDEPTH)\n",
    "                # scale it to [0, 1]\n",
    "                trans_frame = utils.rangescale(trans_frame, rescale=(0, 1))\n",
    "                # get old image size\n",
    "                old_image_height, old_image_width = trans_frame.shape\n",
    "\n",
    "                # if it is bigger, crop it. Not sure if that works well..?\n",
    "                if new_image_height<old_image_height:\n",
    "                    dif = old_image_height - new_image_height\n",
    "                    crop_img = trans_frame[dif:old_image_height, :]\n",
    "                else:\n",
    "                    crop_img = trans_frame\n",
    "                # reevaluate size\n",
    "                old_image_height, old_image_width = crop_img.shape\n",
    "                # init an empty image\n",
    "                color = 0\n",
    "                result = np.full((new_image_height,new_image_width), color, dtype=np.float32)\n",
    "                # compute center offset\n",
    "                x_center = (new_image_width - old_image_width) // 2\n",
    "                y_center = (new_image_height - old_image_height) // 2\n",
    "                # copy img image into center of result image\n",
    "                result[y_center:y_center+old_image_height, \n",
    "                       x_center:x_center+old_image_width] = crop_img\n",
    "                # append these images to the position object\n",
    "                pos.rois[rois_nb].img_stack.append(result)\n",
    "\n",
    "            # same for the segmentation images\n",
    "            seg_fps = sorted(glob.glob((chamber_folders[chami] + '/seg_sd2') + \"/*.tif\"))\n",
    "            for seg_fp in seg_fps:\n",
    "                # read image\n",
    "                seg = cv2.imread(str(seg_fp),cv2.IMREAD_ANYDEPTH)\n",
    "                # get size, crop if needed\n",
    "                old_image_height, old_image_width = seg.shape\n",
    "                if new_image_height<old_image_height:\n",
    "                    dif = old_image_height - new_image_height\n",
    "                    crop_img = seg[dif:old_image_height, :]\n",
    "                else:\n",
    "                    crop_img = seg\n",
    "\n",
    "                old_image_height, old_image_width = crop_img.shape\n",
    "                color = 0\n",
    "                # format new image\n",
    "                if (np.amax(crop_img)>0):\n",
    "                    crop_img *= (255.0/crop_img.max())\n",
    "                crop_img = crop_img.astype('int32')\n",
    "\n",
    "                # get the boundaries of labels, set these to 0\n",
    "                mask = skimage.segmentation.find_boundaries(crop_img, connectivity=1, mode='outer', background=0)\n",
    "                crop_img[mask] = 0\n",
    "\n",
    "                # remove cells that touch upper and lower parts of the image. These are difficult to track\n",
    "                # you may remove that part\n",
    "                bordermask = np.full((old_image_height,old_image_width), 1, dtype=np.float32)\n",
    "                bordermask[:,0:2] = 0\n",
    "                bordermask[:,-3:-1] = 0\n",
    "                bordermask = bordermask.astype(bool)\n",
    "                crop_img = clear_border(np.array(crop_img, dtype=bool), mask = bordermask)\n",
    "\n",
    "                # paste that cleaned up binary image into a new image with correct size\n",
    "                result = np.full((new_image_height,new_image_width), color, dtype=np.float32)\n",
    "                # compute center offset\n",
    "                x_center = (new_image_width - old_image_width) // 2\n",
    "                y_center = (new_image_height - old_image_height) // 2\n",
    "                # copy img image into center of result image\n",
    "                result[y_center:y_center+old_image_height, \n",
    "                   x_center:x_center+old_image_width] = crop_img\n",
    "\n",
    "                result = np.array(result, dtype=bool)\n",
    "                # append it into the seg_stack of the position object\n",
    "                pos.rois[rois_nb].seg_stack.append(result.astype(np.uint8))\n",
    "            \n",
    "            # finally, we track!!\n",
    "            pos.track(list(range(reader.timepoints)))\n",
    "            # and extract features\n",
    "            pos.features(frames=frames, features=features)\n",
    "            # extract lineage object. If this is not empty, save .csv files\n",
    "            lin = pos.rois[0].lineage\n",
    "            if len(lin.cells)>0:\n",
    "                df = delta_to_df(pos)\n",
    "                save_name = save_directory + '/' + 'Pos' + str(round(meta.pos[i])).zfill(2) + chamber_folders[chami][-7:]\n",
    "                df.to_csv(save_name + '.csv' , index=False)\n",
    "                try:\n",
    "                    if savemovie:\n",
    "                        if saved_movies == savemoviefreq:\n",
    "                            pos.save(\n",
    "                                filename=save_name,\n",
    "                                frames=frames,\n",
    "                                save_format=cfg.save_format,\n",
    "                                )\n",
    "                            saved_movies = 0\n",
    "                        saved_movies +=1\n",
    "                except:\n",
    "                    print('error in movie')\n",
    "                    fails = fails + 'Movie:Chamb' + chamber_folders[chami][-7:]\n",
    "                    saved_movies = savemoviefreq-1\n",
    "                    continue\n",
    "        except:\n",
    "                print('any error...')\n",
    "                fails = fails + 'Error:Chamb' + chamber_folders[chami][-7:]\n",
    "                continue\n",
    "        # re-read meta file (this ensures correct status as I run multiple scripts simultaneously that all read and write into it)\n",
    "        meta = pd.read_csv(os.path.join(masterdir,metacsv))\n",
    "        # update status and save\n",
    "        meta.loc[i, ('delta')] = 'Done'\n",
    "        meta.loc[i, ('delta_fails')] = fails\n",
    "        try:\n",
    "            meta.to_csv(os.path.join(masterdir,metacsv), index = False)\n",
    "            today = date.today()\n",
    "            meta.to_csv(os.path.join(masterdir,metacsv+'_' + today.strftime(\"%Y-%m-%d\") + '.csv'), index = False)\n",
    "        except:\n",
    "            print('Close meta  file!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5c5d51-b123-4adf-be4b-8300ea413767",
   "metadata": {},
   "source": [
    "# You are at the end!!\n",
    "\n",
    "Now, have fun exploring your data with whatever other sofware you like :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
