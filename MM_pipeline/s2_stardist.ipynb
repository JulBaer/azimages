{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6636d9d0",
   "metadata": {},
   "source": [
    "# MM pipeline: Run the StarDist2D segmentation model over all folders\n",
    "\n",
    "This notebook loads a pretrained StarDist2D segmentation model and applies the segmentation prediction on all folders within the masterfolder mainf (defined in 2nd code cell). Only microscopy chamber data containing folders should be within mainf. The segmentation is applied onto all images that end with *_PH.tif* and the segmentation image is saved into a newly created folder within each image folder named *seg_sd2*. For the moment, it assumes single-page tif files and saves single-page tif files with the exact same name as the input image used for segmentation prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be194b4",
   "metadata": {},
   "source": [
    "### Load main config file. Adapt directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6037ab35-db6c-4993-95fe-2384b76475ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mainconfigname = 'jbanalysisconfig_mm';\n",
    "configdir = 'C://Users/zinke/Documents/GitHub/azimages/julian/MM_pipeline';\n",
    "\n",
    "if not mainconfigname.endswith('.json'):\n",
    "    mainconfigname += '.json'\n",
    "    \n",
    "if not configdir.endswith('/'):\n",
    "    configdir += '/'\n",
    "\n",
    "import json\n",
    "# Read JSON data\n",
    "with open(configdir+mainconfigname, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Assign each key-value pair as a variable\n",
    "for key, value in data.items():\n",
    "    globals()[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8270a2bc-943c-444b-9229-11bb2c1c965f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load various packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8362889-58a4-41ef-8062-80dbeb95f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "from tifffile import imread, imwrite\n",
    "from datetime import datetime\n",
    "from csbdeep.utils import Path, normalize\n",
    "from skimage.measure import regionprops, regionprops_table\n",
    "from skimage import io\n",
    "from skimage import segmentation\n",
    "from skimage import color\n",
    "from stardist.matching import matching_dataset\n",
    "from stardist import fill_label_holes, random_label_cmap, relabel_image_stardist, calculate_extents, gputools_available, _draw_polygons\n",
    "from stardist.models import Config2D, StarDist2D, StarDistData2D\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "np.random.seed(42)\n",
    "lbl_cmap = random_label_cmap()\n",
    "\n",
    "def add_prefix(props, prefix):\n",
    "    return {f\"{prefix}_{key}\" if 'intensity' in key else key: value for key, value in props.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ae6e8-8712-4f38-9056-05fd1c397602",
   "metadata": {},
   "source": [
    "### Check if GPU can be accessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4fbcd94-85b0-4361-8002-31aa57e2171a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not find scikit-tensor which is needed for separable approximations...\n",
      "If you want to compute separable approximations, please install it with\n",
      "pip install scikit-tensor-py3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gputools_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea17582b-56ed-4f81-b42c-04215b86b637",
   "metadata": {},
   "source": [
    "### Load in meta file and display head. Check if correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5843fccb-8d7a-40ea-919c-2c4e49fc6d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>replicate</th>\n",
       "      <th>pos</th>\n",
       "      <th>strain</th>\n",
       "      <th>dt</th>\n",
       "      <th>channel</th>\n",
       "      <th>Note</th>\n",
       "      <th>Exclude</th>\n",
       "      <th>MaxFr</th>\n",
       "      <th>type</th>\n",
       "      <th>aip_type</th>\n",
       "      <th>...</th>\n",
       "      <th>rotation</th>\n",
       "      <th>StageX</th>\n",
       "      <th>StageY</th>\n",
       "      <th>PxinUmX</th>\n",
       "      <th>PxinUmY</th>\n",
       "      <th>register</th>\n",
       "      <th>stardist</th>\n",
       "      <th>stardist_fails</th>\n",
       "      <th>delta</th>\n",
       "      <th>delta_fails</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s02</td>\n",
       "      <td>1</td>\n",
       "      <td>agr-I</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sAIP</td>\n",
       "      <td>AIP-I</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-62860.49788</td>\n",
       "      <td>-39324.74159</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s03</td>\n",
       "      <td>1</td>\n",
       "      <td>agr-I</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240.0</td>\n",
       "      <td>sAIP</td>\n",
       "      <td>AIP-I</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-59819.89317</td>\n",
       "      <td>-38749.07585</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s06</td>\n",
       "      <td>1</td>\n",
       "      <td>agr-I</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225.0</td>\n",
       "      <td>sAIP</td>\n",
       "      <td>AIP-I</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-60615.52819</td>\n",
       "      <td>-37553.06656</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s06</td>\n",
       "      <td>2</td>\n",
       "      <td>agr-I</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192.0</td>\n",
       "      <td>sAIP</td>\n",
       "      <td>AIP-I</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-61960.15363</td>\n",
       "      <td>-35559.99190</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s07</td>\n",
       "      <td>1</td>\n",
       "      <td>agr-II</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sAIP</td>\n",
       "      <td>AIP-II</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-57633.21060</td>\n",
       "      <td>-43430.12590</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Done</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  replicate  pos  strain   dt  channel  Note  Exclude  MaxFr  type aip_type  \\\n",
       "0       s02    1   agr-I  5.0        2   NaN      NaN    NaN  sAIP    AIP-I   \n",
       "1       s03    1   agr-I  5.0        4   NaN      NaN  240.0  sAIP    AIP-I   \n",
       "2       s06    1   agr-I  5.0        4   NaN      NaN  225.0  sAIP    AIP-I   \n",
       "3       s06    2   agr-I  5.0        5   NaN      NaN  192.0  sAIP    AIP-I   \n",
       "4       s07    1  agr-II  5.0        2   NaN      NaN    NaN  sAIP   AIP-II   \n",
       "\n",
       "   ...  rotation       StageX       StageY  PxinUmX  PxinUmY  register  \\\n",
       "0  ...      0.00 -62860.49788 -39324.74159    0.065    0.065      Done   \n",
       "1  ...      0.00 -59819.89317 -38749.07585    0.065    0.065      Done   \n",
       "2  ...     -0.25 -60615.52819 -37553.06656    0.065    0.065      Done   \n",
       "3  ...     -0.25 -61960.15363 -35559.99190    0.065    0.065      Done   \n",
       "4  ...      0.25 -57633.21060 -43430.12590    0.065    0.065      Done   \n",
       "\n",
       "  stardist  stardist_fails delta  delta_fails  \n",
       "0     Done             NaN   NaN          NaN  \n",
       "1     Done             NaN   NaN          NaN  \n",
       "2     Done             NaN   NaN          NaN  \n",
       "3     Done             NaN   NaN          NaN  \n",
       "4     Done             NaN   NaN          NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pd.read_csv(os.path.join(masterdir,metacsv), dtype={'stardist': str})\n",
    "replicates = meta.replicate.unique()\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383a362e",
   "metadata": {},
   "source": [
    "### Load stardist model\n",
    "Here, the model is loaded. You need to specify the dir which contains a folder named *stardist* in the config file. This *stardist* folder needs to contain the files *weigths_best.h5* as well as the *config.json* and optionally the *thresholds.json*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da3713b5-93e4-4d12-8e15-ace7422c52e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C://Users/zinke/Documents/GitHub/azimages/julian/stardist/models\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.586968, nms_thresh=0.3.\n"
     ]
    }
   ],
   "source": [
    "print(stardistmodeldir)\n",
    "model = StarDist2D(None, name='stardist', basedir=stardistmodeldir)\n",
    "axis_norm = (0,1)   # normalize channels independently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198a983f-591d-4329-9de0-f7351b1d17e3",
   "metadata": {},
   "source": [
    "### Define regionprops parameters. You could add more if you want to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93a8cea5-1872-4fcf-98d2-804f99a854fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if flims:\n",
    "    prop_list = ['label', \n",
    "                'area', 'centroid', \n",
    "                'axis_major_length', 'axis_minor_length',\n",
    "                 'eccentricity',\n",
    "                'intensity_mean', 'intensity_max']\n",
    "else:\n",
    "    prop_list = ['label', \n",
    "                'area', 'centroid', \n",
    "                'axis_major_length', 'axis_minor_length',\n",
    "                 'eccentricity'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f31f0d9-c131-4c66-9b49-57d381335eb7",
   "metadata": {},
   "source": [
    "### Limit GPU RAM usage by StarDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbec354f-3d21-46cd-ad68-12021a62494e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from csbdeep.utils.tf import limit_gpu_memory\n",
    "# adjust as necessary: limit GPU memory to be used by TensorFlow to leave some to OpenCL-based computations\n",
    "limit_gpu_memory(fraction=ramlimit, total_memory=ramsize)\n",
    "# alternatively, try this:\n",
    "# limit_gpu_memory(None, allow_growth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871c295a-9117-459c-a490-959495b3665f",
   "metadata": {},
   "source": [
    "## Main segmentation loop\n",
    "This loop goes over each row in the meta file which is marked with completed preprocessing (Progress == 'Done') and applies the StarDist segmentation model to each position/chamber iteratively. For the moment, not paralellized but could probably benefit from that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f852a07c-a070-4f8e-b21e-df10d0fc29e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s27, Pos 01: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [30:54<00:00, 154.57s/it]\n",
      "s28, Pos 01:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                     | 15/36 [1:10:51<2:06:21, 361.03s/it]"
     ]
    }
   ],
   "source": [
    "for i in range(0, meta.shape[0]): # go over all rows in the meta file\n",
    "    if meta.loc[i, 'stardist'] == 'Done' or meta.loc[i, 'Exclude'] == 'excl' or not meta.loc[i, ('register')] == 'Done':\n",
    "        continue\n",
    "\n",
    "    # Directory setup for current experiment\n",
    "    main_folder = os.path.join(masterdir, savedirname, meta.replicate[i], 'Chambers')\n",
    "    save_directory = os.path.join(main_folder, 'stardistdata')\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "    current_directory = os.path.join(main_folder, f'Pos{str(meta.pos[i]).zfill(2)}')\n",
    "    if not os.path.exists(current_directory):\n",
    "        continue\n",
    "\n",
    "    # get final chamber dir for all of the current position\n",
    "    chambf = [ f.path for f in os.scandir(current_directory) if f.is_dir() ]\n",
    "    chambf = [k for k in chambf if 'Chamb' in k]\n",
    "\n",
    "    fails = []  # To record any failures\n",
    "    for chambi in tqdm(range(0, len(chambf)), desc=meta.replicate[i] + ', Pos ' + str(meta.pos[i]).zfill(2)):\n",
    "        inputs_folder = chambf[chambi]\n",
    "        outputs_folder = os.path.join(inputs_folder, \"seg_sd2\")\n",
    "        os.makedirs(outputs_folder, exist_ok=True)\n",
    "        # Clear output folder if not empty\n",
    "        for file in Path(outputs_folder).glob('*tif'):\n",
    "            os.remove(file)\n",
    "\n",
    "        # Collecting timelapse images\n",
    "        images = sorted(Path(inputs_folder).glob('*Ch1*tif'))\n",
    "        # Additional channels if applicable\n",
    "        if flims:\n",
    "            images_fl = sorted(Path(inputs_folder).glob('*Ch2*tif'))\n",
    "            if n_channel > 2:\n",
    "                images_fl2 = sorted(Path(inputs_folder).glob('*Ch3*tif'))\n",
    "\n",
    "        # Determine frame range\n",
    "        max_frame = meta.loc[i, 'MaxFr']\n",
    "        frame_list = range(len(images)) if np.isnan(max_frame) else range(int(max_frame) - 1)\n",
    "\n",
    "        # Process each frame\n",
    "        for frame_index in frame_list:\n",
    "            try:\n",
    "                # Reading fluorescence images if available\n",
    "                if flims:\n",
    "                    fluorescence_image = imread(images_fl[frame_index])\n",
    "                    if n_channel > 2:\n",
    "                        fluorescence_image2 = imread(images_fl2[frame_index])\n",
    "\n",
    "                # Main segmentation process\n",
    "                main_image = imread(images[frame_index])\n",
    "                normalized_image = normalize(main_image, 1, 99.8, axis=axis_norm)\n",
    "                labels, details = model.predict_instances(normalized_image)\n",
    "\n",
    "                # Save segmentation labels\n",
    "                filename_segmentation = os.path.join(outputs_folder, os.path.basename(images[frame_index]))\n",
    "                imwrite(filename_segmentation, labels, append=False, metadata=None)\n",
    "\n",
    "                # Region properties calculation\n",
    "                region_props = regionprops_table(labels, intensity_image=fluorescence_image if flims else None, properties=prop_list)\n",
    "                if flims and n_channel > 2:\n",
    "                    region_props = add_prefix(region_props, 'fluor1')\n",
    "                    region_props2 = regionprops_table(labels, intensity_image=fluorescence_image2, properties=prop_list)\n",
    "                    region_props2 = add_prefix(region_props2, 'fluor2')\n",
    "                    # Merge intensity data for multiple fluorescence channels\n",
    "                    for key, value in region_props2.items():\n",
    "                        if 'intensity' in key:\n",
    "                            region_props[key] = value\n",
    "\n",
    "                # Dataframe handling: compile and format region properties\n",
    "                region_props_df = pd.DataFrame(region_props)\n",
    "                region_props_df.insert(0, 'frame', frame_index + 1)\n",
    "                region_props_df.insert(0, 'pos', int(os.path.basename(current_directory)[-2:]))\n",
    "                region_props_df.insert(0, 'replicate', meta.replicate[i])\n",
    "                region_props_df.insert(2, 'chamber', int(os.path.basename(inputs_folder)[-2:]))\n",
    "                region_props_df['folder'] = current_directory\n",
    "\n",
    "                if frame_index == 0:\n",
    "                    all_frames_df = region_props_df\n",
    "                else:\n",
    "                    all_frames_df = pd.concat([all_frames_df, region_props_df], ignore_index=True)\n",
    "\n",
    "            except Exception as e:\n",
    "                # Log any errors encountered during processing\n",
    "                fails.append(f\"Error processing folder {current_directory}, Frame {frame_index}: {e}\")\n",
    "\n",
    "                # Save compiled data for current position\n",
    "            if 'all_frames_df' in locals():\n",
    "                all_frames_df.to_csv(os.path.join(save_directory, os.path.basename(current_directory) + '.csv'), index=False)\n",
    "\n",
    "    # Update metadata to indicate completion and log any failures\n",
    "    meta = pd.read_csv(os.path.join(masterdir,metacsv), dtype={'stardist': str})\n",
    "    meta.at[i, 'stardist'] = 'Done'\n",
    "    if fails:\n",
    "        meta.at[i, 'stardist_fails'] = '; '.join(fails)\n",
    "\n",
    "    # Save metadata with updates\n",
    "    meta.to_csv(os.path.join(masterdir, metacsv), index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea1ffed-7961-495e-9f5d-d6af42f5c099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
